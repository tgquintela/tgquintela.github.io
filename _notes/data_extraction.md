---
title: "# Data extraction
"
collection: notes
permalink: /notes/data_extraction
date: 2016-06-01

---

# Data extraction

2016-06-01

Data extraction is the act or process of retrieving data out of (usually unstructured or poorly structured) data sources for further data processing or data storage (data migration). The import into the intermediate extracting system is thus usually followed by data transformation and possibly the addition of metadata prior to export to another stage in the data workflow.

Usually, the term data extraction is applied when (experimental) data is first imported into a computer from primary sources, like measuring or recording devices. 

Typical unstructured data sources include web pages, emails, documents, PDFs, scanned text, mainframe reports, spool files, classifieds, etc. Which is further used for sales / marketing leads. Extracting data from these unstructured sources has grown into a considerable technical challenge where as historically data extraction has had to deal with changes in physical hardware formats, the majority of current data extraction deals with extracting data from these unstructured data sources, and from different software formats. This growing process of data extraction from the web is referred to as Web scraping.

The act of adding structure to unstructured data takes a number of forms:
* Using text pattern matching such as regular expressions to identify small or large-scale structure e.g. records in a report and their associated data from headers and footers;
* Using a table-based approach to identify common sections within a limited domain using a standard set of commonly used headings (these would differ from language to language)
* Using text analytics to attempt to understand the text and link it to other information

Related with data extraction there are different associate concepts:
* Data transfer between programs is accomplished using data structures suited for automated processing by computers, not people. Such interchange formats and protocols are typically rigidly structured, well-documented, easily parsed, and keep ambiguity to a minimum. Very often, these transmissions are not human-readable at all.
* Data scraping: is a technique in which a computer program extracts data from human-readable output coming from another program.
* Data modeling: design the desired structure database to fit our purposes.

***Tags***: Data science

#### See also
[Data munging](/notes/data_munging), [Data visualization](/notes/data_visualization)

## Material
* https://myhelpster.com/what-is-scraping-the-basics-for-everyone/




